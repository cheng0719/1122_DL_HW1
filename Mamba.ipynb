{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae11488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange, repeat\n",
    "from typing import Union\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import datasets\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b74f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                              shape=(int(self.seq_len),),\n",
    "                                              initializer='uniform',\n",
    "                                              trainable=True)\n",
    "\n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                           shape=(int(self.seq_len),),\n",
    "                                           initializer='uniform',\n",
    "                                           trainable=True)\n",
    "\n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                                shape=(int(self.seq_len),),\n",
    "                                                initializer='uniform',\n",
    "                                                trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                             shape=(int(self.seq_len),),\n",
    "                                             initializer='uniform',\n",
    "                                             trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''Calculate linear and periodic time features'''\n",
    "        x = tf.math.reduce_mean(x[:, :, :4], axis=-1)\n",
    "        time_linear = self.weights_linear * x + self.bias_linear  # Linear time feature\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
    "\n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1)  # shape = (batch, seq_len, 2)\n",
    "\n",
    "    def get_config(self):  # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31521e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    model_input_dims: int = 64\n",
    "    model_states: int = 64\n",
    "    projection_expand_factor: int = 2\n",
    "    conv_kernel_size: int = 4\n",
    "    delta_t_min: float = 0.001\n",
    "    delta_t_max: float = 0.1\n",
    "    delta_t_scale: float = 0.1\n",
    "    delta_t_init_floor: float = 1e-4\n",
    "    conv_use_bias: bool = True\n",
    "    dense_use_bias: bool = False\n",
    "    layer_id: int = -1\n",
    "    seq_length: int = 30  # 30 days stock price data\n",
    "    num_layers: int = 5\n",
    "    dropout_rate: float = 0.2\n",
    "#     use_lm_head: float = False\n",
    "#     num_classes: int = None\n",
    "#     vocab_size: int = None\n",
    "#     final_activation = None\n",
    "#     loss:Union[str, keras.losses.Loss] = None\n",
    "    loss: str = 'mse'\n",
    "#     optimizer: Union[str, keras.optimizers.Optimizer] = keras.optimizers.AdamW()\n",
    "    optimizer: str = 'adam'\n",
    "    metrics = ['mae', 'mape']\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n",
    "\n",
    "        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n",
    "        if self.layer_id == -1:\n",
    "            self.layer_id = np.round(np.random.randint(0, 1000), 4)\n",
    "\n",
    "#         if self.vocab_size == None:\n",
    "#             raise ValueError(\"vocab size cannot be none\")\n",
    "\n",
    "#         if self.use_lm_head:\n",
    "#             self.num_classes=self.vocab_size\n",
    "#         else:\n",
    "#             if self.num_classes == None:\n",
    "#                 raise ValueError(f'num classes cannot be {self.num_classes}')\n",
    "\n",
    "#             if self.num_classes == 1:\n",
    "#                 self.final_activation = 'sigmoid'\n",
    "#             else:\n",
    "#                 self.final_activation = 'softmax'\n",
    "\n",
    "#         if self.loss == None:\n",
    "#             raise ValueError(f\"loss cannot be {self.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f68447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ecfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_scan(u, delta, A, B, C, D):\n",
    "    # first step of A_bar = exp(ΔA), i.e., ΔA\n",
    "    dA = tf.einsum('bld,dn->bldn', delta, A) \n",
    "    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n",
    "    \n",
    "    dA_cumsum = tf.pad(\n",
    "        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n",
    "    \n",
    "    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n",
    "    \n",
    "    # Cumulative sum along all the input tokens, parallel prefix sum, \n",
    "    # calculates dA for all the input tokens parallely\n",
    "    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)  \n",
    "\n",
    "    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n",
    "    dA_cumsum = tf.exp(dA_cumsum)  \n",
    "    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n",
    "\n",
    "    x = dB_u * dA_cumsum\n",
    "    # 1e-12 to avoid division by 0\n",
    "    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12) \n",
    "\n",
    "    y = tf.einsum('bldn,bln->bld', x, C)\n",
    "    \n",
    "    return y + u * D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcb4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaBlock(Layer):  # layers.\n",
    "    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.args = modelargs\n",
    "        args = modelargs\n",
    "        self.layer_id = modelargs.layer_id\n",
    "\n",
    "#         self.in_projection = layers.Dense(\n",
    "#             args.model_internal_dim * 2, \n",
    "#             input_shape=(args.model_input_dims,), use_bias=False)\n",
    "        self.in_projection = Dense(\n",
    "            args.model_internal_dim * 2, \n",
    "            input_shape=(args.model_input_dims,), use_bias=False)\n",
    "\n",
    "#         self.conv1d = layers.Conv1D(\n",
    "#             filters=args.model_internal_dim,\n",
    "#             use_bias=args.conv_use_bias,\n",
    "#             kernel_size=args.conv_kernel_size,\n",
    "#             groups=args.model_internal_dim,\n",
    "#             data_format='channels_first',\n",
    "#             padding='causal'\n",
    "#         )\n",
    "        self.conv1d = Conv1D(\n",
    "            filters=args.model_internal_dim,\n",
    "            use_bias=args.conv_use_bias,\n",
    "            kernel_size=args.conv_kernel_size,\n",
    "            groups=args.model_internal_dim,\n",
    "            data_format='channels_first',\n",
    "            padding='causal'\n",
    "        )\n",
    "\n",
    "        # this layer takes in current token 'x' \n",
    "        # and outputs the input-specific Δ, B, C (according to S6)\n",
    "#         self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n",
    "        self.x_projection = Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n",
    "\n",
    "        # this layer projects Δ from delta_t_rank to the mamba internal \n",
    "        # dimension\n",
    "#         self.delta_t_projection = layers.Dense(args.model_internal_dim, \n",
    "#                                                input_shape=(args.delta_t_rank,), use_bias=True)\n",
    "        self.delta_t_projection = Dense(args.model_internal_dim, \n",
    "                                               input_shape=(args.delta_t_rank,), use_bias=True)\n",
    "\n",
    "        self.A = repeat(\n",
    "                tf.range(1, args.model_states+1, dtype=tf.float32), \n",
    "                'n -> d n', d=args.model_internal_dim)\n",
    "\n",
    "        self.A_log = tf.Variable(\n",
    "                tf.math.log(self.A), \n",
    "                trainable=True, dtype=tf.float32, \n",
    "                name=f\"SSM_A_log_{args.layer_id}\")\n",
    "\n",
    "        self.D = tf.Variable(\n",
    "                np.ones(args.model_internal_dim), \n",
    "                trainable=True, dtype=tf.float32, \n",
    "                name=f\"SSM_D_{args.layer_id}\")\n",
    "\n",
    "#         self.out_projection = layers.Dense(\n",
    "#                 args.model_input_dims, \n",
    "#                 input_shape=(args.model_internal_dim,), \n",
    "#                 use_bias=args.dense_use_bias)\n",
    "        self.out_projection = Dense(\n",
    "                args.model_input_dims, \n",
    "                input_shape=(args.model_internal_dim,), \n",
    "                use_bias=args.dense_use_bias)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n",
    "        Official Implementation:\n",
    "            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "        \"\"\"\n",
    "\n",
    "        (batch_size, seq_len, dimension) = x.shape\n",
    "\n",
    "        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n",
    "        (x, res) = tf.split(x_and_res, \n",
    "                            [self.args.model_internal_dim, \n",
    "                             self.args.model_internal_dim], axis=-1)\n",
    "        \n",
    "        x = rearrange(x, 'b l d_in -> b d_in l')\n",
    "        x = self.conv1d(x)[:, :, :seq_len]\n",
    "        x = rearrange(x, 'b d_in l -> b l d_in')\n",
    "        \n",
    "        x = tf.nn.swish(x)\n",
    "        y = self.ssm(x)\n",
    "        y = y * tf.nn.swish(res)\n",
    "        return self.out_projection(y)\n",
    "    \n",
    "    def ssm(self, x):\n",
    "        \"\"\"Runs the SSM. See:\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4\n",
    "            Official Implementation:\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "        \"\"\"\n",
    "        (d_in, n) = self.A_log.shape\n",
    "\n",
    "        # Compute ∆ A B C D, the state space parameters.\n",
    "        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n",
    "        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n",
    "        #                                  and is why Mamba is called **selective** state spaces)\n",
    "\n",
    "        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n",
    "        D = tf.cast(self.D, tf.float32)\n",
    "\n",
    "        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n",
    "\n",
    "        (delta, B, C) = tf.split(\n",
    "                x_dbl, \n",
    "                num_or_size_splits=[self.args.delta_t_rank, n, n], \n",
    "                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n",
    "\n",
    "        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n",
    "\n",
    "        return selective_scan(x, delta, A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278e28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):  # layers.\n",
    "    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.args = modelargs\n",
    "        self.mixer = MambaBlock(modelargs)\n",
    "        self.norm = LayerNormalization(epsilon=1e-5)  # layers.  deleted\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Official Implementation:\n",
    "            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n",
    "            \n",
    "            Note: the official repo chains residual blocks that look like\n",
    "                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n",
    "            where the first Add is a no-op. This is purely for performance reasons as this\n",
    "            allows them to fuse the Add->Norm.\n",
    "\n",
    "            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n",
    "                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n",
    "            \n",
    "        \"\"\"\n",
    "        return self.mixer(self.norm(x)) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93dc460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args: ModelArgs):\n",
    "    time_embedding = Time2Vector(args.seq_length)\n",
    "    \n",
    "    input_layer = Input(shape=(args.seq_length,1), name='input_ids') # layers.\n",
    "#     x = layers.Embedding(\n",
    "#                 args.vocab_size, \n",
    "#                 args.model_input_dims, \n",
    "#                 input_length=args.seq_length)(input_layer)\n",
    "    x = time_embedding(input_layer)\n",
    "    x = Concatenate(axis=-1)([input_layer, x]) # layers.\n",
    "\n",
    "    for i in range(args.num_layers):\n",
    "        x = ResidualBlock(args, name=f\"Residual_{i}\")(x)\n",
    "        x = Dropout(args.dropout_rate)(x) # for regularization  # layers.\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-5)(x) # normalization layer  # layers.\n",
    "    \n",
    "    # use flatten only if we are not using the model as an LM\n",
    "    # if not args.use_lm_head: \n",
    "    x = Flatten()(x) # layers.\n",
    "    x = Dense(64, activation=tf.nn.gelu)(x)  # layers.\n",
    "    x = Dropout(0.1)(x)                     # consider to use args.dropout  # layers.\n",
    "    output_layer = Dense(1, activation='linear')(x)  # layers.\n",
    "#     output_layer = layers.Dense(\n",
    "#                 args.num_classes, \n",
    "#                 activation=args.final_activation)(x)\n",
    "\n",
    "    model = Model(\n",
    "                inputs=[input_layer], \n",
    "                outputs=[output_layer], name='Mamba_ka_Mamba')\n",
    "    model.compile(\n",
    "        loss=args.loss,\n",
    "        optimizer=args.optimizer,\n",
    "        metrics=args.metrics\n",
    "    )\n",
    "#     model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2919720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Mamba_ka_Mamba\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Mamba_ka_Mamba\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time2_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Time2Vector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ time2_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Residual_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Residual_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Residual_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Residual_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Residual_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,824</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time2_vector_1 (\u001b[38;5;33mTime2Vector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m)             │             \u001b[38;5;34m120\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ time2_vector_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_0 (\u001b[38;5;33mResidualBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m492\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ Residual_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_1 (\u001b[38;5;33mResidualBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m492\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ Residual_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_2 (\u001b[38;5;33mResidualBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m492\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ Residual_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_3 (\u001b[38;5;33mResidualBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m492\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ Residual_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Residual_4 (\u001b[38;5;33mResidualBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m492\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ Residual_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │               \u001b[38;5;34m6\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m5,824\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,475</span> (33.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,475\u001b[0m (33.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,475</span> (33.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,475\u001b[0m (33.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = ModelArgs(\n",
    "    model_input_dims=3,\n",
    "    model_states=32,\n",
    "#     num_layers=12,\n",
    "    dropout_rate=0.2,\n",
    "#     vocab_size=vocab_size,\n",
    "#     num_classes=1,\n",
    "#     loss='binary_crossentropy',\n",
    ")\n",
    "model = init_model(args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef356c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          close\n",
      "date           \n",
      "20100104     64\n",
      "20100105     64\n",
      "20100106     64\n",
      "20100107     64\n",
      "20100108     64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "tsmc_data = pd.read_csv('./tsmc_stock_prices_INT_close_only.csv')\n",
    "tsmc_data.index = tsmc_data[\"date\"]\n",
    "tsmc_data = tsmc_data.drop(columns=[\"date\"])\n",
    "print(tsmc_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f646ded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:(2718, 30)\n",
      "y_train.shape:(2718, 1)\n",
      "x_test.shape:(680, 30)\n",
      "y_test.shape(680, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "input_length = 30\n",
    "output_length = 1\n",
    "test_percentage = 0.2\n",
    "dataset = tsmc_data['close'].to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_norm = scaler.fit_transform(dataset.reshape(-1, 1)).flatten()\n",
    "dataset_list = []\n",
    "for i in range(len(dataset) - input_length - output_length):\n",
    "    dataset_list.append(dataset_norm[i:i + input_length + output_length])\n",
    "dataset_list = np.array(dataset_list)\n",
    "trainset = dataset_list[:int(len(dataset_list) * (1 - test_percentage))]\n",
    "testset = dataset_list[int(len(dataset_list) * (1 - test_percentage)):]\n",
    "\n",
    "x_train = trainset[:, :-1]\n",
    "y_train = trainset[:, -1:]\n",
    "x_test = testset[:, :-1]\n",
    "y_test = testset[:, -1:]\n",
    "\n",
    "print('x_train.shape:' + str(x_train.shape))\n",
    "print('y_train.shape:' + str(y_train.shape))\n",
    "print('x_test.shape:' + str(x_test.shape))\n",
    "print('y_test.shape' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745897d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
